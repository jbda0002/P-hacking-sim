\section{Discussion}
There is an increasing awareness among scientists that we need to increase the replicability of research by lowering the number of false positive findings that get published. One way to reduce false positive findings is with preregistration of a single data plan for pre-processing and analysis since this removes researcher flexibilities that can otherwise inflate the risk of false positives \citep{Simmons2011}. However, even with a plan for pre-processing and analysis there is a risk that the false positive probability may be higher than 5\%. Simulation research show that type I error rates can increase for several reasons such as model misspecification, noise or ceiling effects in independent variables, or dichotomization of continuous covariates \citep{Dennis2019, Litiere2007, Brunner2009, Austin2003, Austin2004}. To better understand the effectiveness of preregistration on false positive rates we used a simulation to examine how FPP and FPR were affected by different flexibilities. Specifically, we looked into the following flexibilities; constructing a model set with several covariates, using multiple outlier criteria, and collecting different dependent variables. We also examined how the precision of the estimates (a bigger sample) and the correlations between the dependent variable and the covariates affected the ability to find a significant effect both when the study would be labeled as exploratory but also under the criteria of preregistration. 

In general preregistration helps a lot with lowering the risk of finding a significant result. However, it is not enough to lower the FPR to 5\%  in all cases. This happens when main effects are not included and the covariates are dummy coded. In this case the FPR can exceed 35\%, meaning that when the researcher just runs one random model from a given set there is already a FPP at 35\%. This happens due to the fact that the interaction effect captures the true effect that would have been in the main effect. So even though some literature still suggest that one can exclude the main effect when doing interactions as long as it is theory based, there seems to be no good reason for this as long as the covariates are dummy coded. This also means that the FPR falls as soon as the variable is effects coded, but it is still above a FPR of 5\%. The only way to overcome this issue is to always include the main effect when interaction effects are of interest. However, even in the sets that include the main effects and interactions the FPR will still be slightly higher than 5\%. This is due to the fact that multiple test's are performed at at the same time. A simple solution to overcome this issue is to correct the p-values for multiple tests, such as using Bonferroni correction \citep{dunn1961multiple} (See figure in SI).  
Given that it is possible to get a FPP of 100\%, labeling research that goes further than the preregistered analysis as exploratory can have little to no meaning. Even with doing correct analysis as including all the constitutive terms and correcting p-values to follow the amount of test in a given model the FPP is still higher than 5\%. P-values are therefore not a good indicator for an effect if the analysis was exploratory. 
    
It has been suggested that one way to lower the FPP would be to ensure a big enough sample \citep{Simmons2011}. Even though this recommendation has been softened a bit, the same suggestion still holds, increase the sample could help with lowering the FPP \cite{simmons2018}. This is however not a reasonable way to lower the FPP or the FPR. And even worse, if using some bad practices, having a big sample can ensure that one would find a significant result. It is still the case that low power can increase the effect size of non significant results (REF), but expecting that it will lower the FPP and FPR is not the case for any model set. 

There is still thing that is out of the control of the researcher, such as the correlation between the covariates. But it still is worth a mention, that the higher correlated the variables are, the easier it is to find a significant model, this is the case both for exploratory analysis and for preregistered analysis. How to solve this problem, is however not as clear as the other issues. 

As one would expect using several flexibilities increase the risk of finding a significant model even though no effect is present. But more surprisingly, preregistration does not seem to be enough to solve the problem. We therefore have the following recommendations to lower the chance of getting a false positive result. 

\subsection{Recommendations}
\hfill\\
Guidelines for researchers 
\hfill\\
\subsubsection{Follow the principals and guidelines of open science}
Since this still insures that the researchers can not use several flexibilities this might be the most important one. Researchers should therefore follow the guidelines already developed (Nosek et al., 2015). This means that research should be preregistered and all data and code should be made available for other researchers to make it easier to see if any mistakes occurred during the analysis. 
\subsubsection{Use Bonferroni corrections when looking at interactions.}
When running regressions with interaction effects a Bonferroni correction should be used. If this is not being done the FPR will be higher than 5\%, and therefore the FPP would also be higher than 5\%. In some cases this can lower the FPR to lower than 5\%, but we think that this is a better outcome than having one that is higher than 5\%. 
\subsubsection{Big enough sample does not guard against FPP and FPR}
Having a big enough sample does not make it better to due exploratory analysis. In general, the sample size does only help with the power of the study and the precision of the estimates, it does not help with lowering FPR and FPP. 

\hfill\\
Guidelines for reviewer and editors
\hfill\\
\subsubsection{Look for correction of p-values}
If multiple comparisons are being made or interaction effects are used, there should be a correction of the p-values
\subsubsection{Demand main effects follow interaction effects}
If the main effect is not included when interaction effects are investigated there should be a thorough explanation of why this is the case.

\subsection{Additional Contributions}
It is not only for researchers who care about false positives in researcher the developed model set specification can help think about the consequences of flexibilities. This also gives a way for researchers who work with machine learning to talk about different parts of the model set with some minor changes in the sets. Since researchers who work with machine learning rarely care about one specific variable but rather the predictability of a general model, having the set HCI is not meaning full. Rather it matters with the level of interactions that would be allowed into the model set and how this expand the model set. We therefore instead splitting the CCI set into how many levels of interactions are allowed. In Table ... can be seen the number of models for the different sets with and without the restriction of having constitutive terms. As for the the calculations for the other model set the derivation of the sets can be found in supplementary information. 


 
