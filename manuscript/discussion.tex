\section{Discussion}
There is a growing awareness among researchers of the need to lower the number of false-positive results reported in the scientific literature. One way to reduce false-positive results is by preregistering a single data plan for pre-processing and analysis since this removes researcher flexibilities that can otherwise inflate the risk of false-positives \citep{simmons2018}. However, there is an ongoing discussion about the effectiveness of this procedure (see e.g. \cite{Pham2020} and \cite{Simmons2020}). While researcher flexibilities such as the use of outlier criteria or multiple dependent variables are often featured as the main cause of false-positive results \citep{John2012}, previous research has shown that conditions such as model misspecification, noise or ceiling effects in the independent variables, or dichotomization of continuous covariates may also lead to type I error rates beyond 5\% \citep{Dennis2019, Litiere2007, Brunner2009, Austin2003, Austin2004}. \\

Using a simulation approach, we examine the role of various data structure and data analysis conditions in generating false-positive results: constructing a model set with several covariates, allowing for interactions with and without main effects being present, using different sample sizes, and the strength of correlations between the dependent variable and the covariates. We examine the effect of these conditions on the false-positive probability (FPP) i.e., the chance of erroneously finding one or more significant effects among all the tested models, and on the false-positive ratio (FPR) i.e., the ratio of  false-positive models to all tested models. The FPP tells us what the probability of a false-positive result is if a researcher tests all models and flexibilities. This metric is informative about exploratory analyses that is, when there is no clear plan beforehand regarding what should be analysed. The FPR tells us about the probability of a false-positive result if a researcher only tests one model under certain conditions. This means that the FPR can be seen as the risk of a false-positive result for researchers that preregister their analysis plan. \\

%but where in many cases it is not clear beforehand which outlier criteria to use or how the different variables should enter the model (e.g., only as main effects or also as interactions). It should be stated that when we talk about preregistration here, we talk about a preregistration in a perfect form, meaning that it is clear beforehand what is being analysed, what the variables of interest are, and which variables one needs to control for. However, this is not always clear from the beginning and these decisions can have an influence on the outcome of the analysis \citep{Bryan25535,gilbert2016comment}.\\ 

%Our findings show that under some conditions, the FPP is as high as 99\%. There are several ways to obtain this result. In general, the covariates need to be binary and dummy coded and models should include interactions between the variable of interest and the covariates and exclude corresponding main effects. For these conditions, a 99\% FPP can be obtained with just two covariates and a large enough sample (see Figure 4). Alternatively, a 99\% FPP can also be obtained with a smaller sample and more than two covariates (see Figure 3). For these conditions, the FPR is as high as 35\%. In general, across data types, correlation structures, sample sizes, uses of outlier criteria or multiple dependent variables the danger lies in models with interactions between the variable of interest and the covariates. Such models always exceed a FPR of 5\%. 

Our findings show that in many cases the FPR lies in the vicinity of the expected 5\%, which is an indicator that preregistration is generally very helpful for lowering the risk of obtaining a false-positive result. However, preregistration is not always sufficient to reach the desired 5\%. In particular, preregistration does not help when using interactions without main effects and especially when covariates are binary and dummy coded. In this case, the FPR can reach 34.5\%. This happens due to the fact that the interaction effect captures the true effect of the covariate that would have otherwise been expressed as a significant main effect of the covariate. Although some authors suggests that one can omit main effects in models with interaction effects when it is theoretically justified, there is a clear statistical reason not to do this, especially when covariates are binary and dummy coded. One way to mitigate this issue is to always include main effects when interaction effects are of interest. However, even so, the FPR will still be slightly higher than 5\%. This is due to the fact that multiple tests are performed at the same time. This may then require an adjustment of the p-value such as Bonferroni correction \citep{dunn1961multiple}. Our calculations show that a Bonferroni correction can in fact remedy the issue and bind the FPR at the level 0.05 regardless of the model specification (see \textit{Supplementary Information} in section \nameref{resultBC}) . \\

Given the ease with which one can obtain an FPP of 100\% the usefulness of significance tests in exploratory analyses is questionable. Even when correctly performing analyses such as including all corresponding main effects to interaction effects and using Bonferroni correction to obtain a desired FPR, the FPP is still higher than 5\% (see Figure \ref{fig:mainfigure1} with restrictions on main effects). A standard approach to significance testing is therefore problematic for determining the presence of an effect if the analysis is exploratory. An alternative could be a more severe threshold for significance (see suggestions by \cite{benjamin2018}) or focusing on effect sizes rather than significance levels. \\
    
It has been suggested that one way to lower the FPP is to ensure sufficient statistical power by having enough observations per cell to detect a true effect \citep{Simmons2011, simmons2018}. This is, however, not an effective way to lower neither the FPP nor FPR. In most cases, the sample size does not affect either the FPP or FPR, but under some conditions, such as when leaving out main effects when using interactions, larger samples can actually increase the FPP and FPR. This may seem counter-intuitive. However, we should bear in mind that here we investigate how often a true null effect can become significant. In a situation where there is a true effect, a larger sample is indeed necessary as small samples can produce exaggerated effects or even effects in the opposite direction \citep{gelman2014beyond}. We do not recommend using small sample sizes, but simply point out that having a large sample does not guarantee an FPP or FPR of 5\%. \\

We also tested the influence of the correlation structure between the dependent variable and covariates. The true correlation structure is often unknown to the researcher, but can in some cases be inferred from prior literature using similar measures. We find that the higher the correlation between the covariates and dependent variable, the easier it is to find a model with a false-positive result both in a single preregistered analysis and exploratory analyses. However, this only holds for models with interaction effects between the variable of interest and covariates. Study designs with common method bias i.e., that measure all covariates in one survey, could be particularly problematic due to the increased correlation between the variables \citep{podsakoff2003}. A potential remedy could be to report correlation matrices which would allow readers to assess whether there is an increased risk of false-positive findings.  \\ 

To summarize, our findings reinforce some well-known measures against false-positive results, but also suggest several new ones. First and foremost researchers should follow guidelines for preregistration \citep{Nosek2015,VANTVEER20162} which reduces the number of researcher flexibilities such as the use of outlier criteria, multiple dependent variables, or testing multiple models. Second, Bonferroni corrections should be used when running regressions with interaction effects to avoid having the FPP and FPR higher than 5\%. Third, when testing interaction effects models should always include the corresponding main effects. Fourth, having a large sample does not legitimize exploratory analyses. In general, the sample size only affects the power of the study and the precision of the estimates, it does not remedy the FPP and FPR. Fifth, researchers should be careful about drawing conclusions based on significance tests in exploratory analyses. Effects should be gauged using other measures of statistical importance or alternatively alpha levels should be set at a very conservative level. \\

Researchers who wish to go against these recommendations for theoretical or other reasons are advised to show by simulation that their analysis does not have an inflated risk of generating false-positive results or if finding that it does have a higher risk, adjusting the alpha level to mitigate the issue. In general, we believe it would be useful always to supplement power analyses with Type I error analyses similar to the ones reported here. The theoretical assumption in power analysis is that Type I error rates are determined by the alpha level, but our findings show that this is often not the case.


%The size of a given model set and its permutations may not only be of interest to the open-science community. Our description of model sets could also be of interest to researchers that use machine learning as a model-selection tool. Since researchers who work with machine learning rarely care about one specific variable but rather about the predictability of a general model, using the sets where HCI is included is not always meaningful. Instead, what matters is whether a researcher will allow for interactions between the independent variables. The calculations of the model sets are therefore the same as if there was a variable of interest, but excluding the sets that have HCI in it. This suggests that considering the restriction that main effects should always follow along with interactions, the sets of interest here are ME and ME + CCI. With no such restriction, the sets of interest are ME, CCI, and ME + CCI. The number of models with and without restrictions, different number of variables, and how to calculate them can be found in Table S9 and Table S10. 


 
