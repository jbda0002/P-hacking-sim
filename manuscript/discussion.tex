\section{Discussion}
There is an increasing awareness among scientists that we need to  lower the number of false positive findings to increase the replicability of research. One way to reduce false positive findings is by preregistering a single data plan for pre-processing and analysis since this removes researcher flexibilities that can otherwise inflate the risk of false positives \citep{Simmons2018}. However, even with a plan for pre-processing and analysis there is still a risk that the FPP may be higher than 5\%. Simulation research shows that type I error rates can increase for several reasons such as model misspecification, noise or ceiling effects in independent variables, or dichotomization of continuous covariates \citep{Dennis2019, Litiere2007, Brunner2009, Austin2003, Austin2004}. To better understand the consequences of exploratory analysis where multiple testing can take place, and how it would look if a study was preregistered such that only one test can be made, we used a simulation to examine both how the FPP and FPR were affected by different flexibilities. Specifically, we looked into the following flexibilities: constructing a model set with several covariates, allowing for interactions with and without main effects, using multiple outlier criteria, and collecting multiple dependent variables. We also examined how the precision of the estimates (a larger sample) and the correlations between the dependent variable and the covariates affected the ability to find a significant effect. \\

When we talk about analysis where we use FPP and FPR as measurement for the consequences of flexibilities, we can interpret these in different ways. The FPP tells us what is the probability that a researcher will get a false-positive result if he was to test all models and flexibilities. This kind of measurement is important when we talk about exploratory analysis where there is no clear plan for what should be analysed. Whereas the FPR tells us the chance of a false-positive result if the researcher is not sure about the model or what outlier criteria to use and then by random pick one of them in a given set and only test that one. This means that the FPR result can be seen as risk of a  false-positive result for a researcher that preregister his analysis plan where it in many cases are not clear beforehand hat outlier criteria to use or how the different variables should enter the model (i.e., only as main effects or as interactions).
It should be mentioned that when we talk about preregistration here, we talk about a preregistration in a perfect form (if one like this exists), meaning that it is clear what is being analysed, what the variables of interest are and what variables one needs to control for. However, this is not always clear and these decisions can have an influence on the outcome of the analysis \citep{Bryan25535,gilbert2016comment}.\\ 

In many cases the FPR lies in the expected neighborhood of around 5\% which is an indicator that preregistration is very helpful lowering the risk of obtaining a false-positive result. However, not in all cases is the preregistration itself sufficient to lower the FPR to the desired 5\%. In particular, the preregistration does not help when the main effects are not included in the model and the covariates are dummy coded. In this case, the FPR can reach 42\%, meaning that on average 42\% of the models in a given set contain a significant effect (either the interaction or the main effect). This happens due to the fact that the interaction effect captures the true effect that would have been in the main effect of the covariate. So even though some literature still suggests that one can exclude the main effect when having interactions as long as it is theory based, there seems to be no good reason for this when the covariates are dummy coded. When the variables are effects coded, the FPR decreases, but it is still above 5\%. The only way to overcome this issue is to always include the main effects when the interaction effects are of interest. However, even then, the FPR will still be slightly higher than 5\%. This is due to the fact that multiple tests are performed at the same time. A simple solution to overcome this issue is to correct the p-values by  using a correction such as Bonferroni correction \citep{dunn1961multiple} (see Figure S6).
 \\

Given that it is possible to obtain an FPP of 100\% even when preregistering one's research plan, labeling research that goes beyond the main analysis as exploratory can have little to no meaning if using p-values. Even when performing correct analyses such as including all the main effects when doing interactions and correcting p-values to follow the number of tests in a given model, the FPP is still higher than 5\%. P-values are therefore not a good indicator for determining the presence of an effect if the analysis is exploratory. This is not to say that exploratory research does not have its value, but using p-values might not be a good indicator for if an exploratory analysis is of interest. \\
    
It has been suggested that one way to lower the FPP would be to ensure having a well-powered study, that is enough observations per cell to detect a true effect \citep{Simmons2011, simmons2018}. This is, however, not an effective way to lower the FPP or FPR since, in combination with bad practices (e.g., leaving out main effects when using interactions), larger samples can produce higher rates of the FPP. This may seem counter-intuitive; however, the reader should bear in mind that in this article we investigated how often a true null effect can become significant. In a situation where there is a true effect, a bigger sample is indeed needed as small samples can produce exaggerated effects or effects in the opposite direction to the true direction \citep{gelman2014beyond}. We do not recommend to run studies with small sample sizes, but simply remind that just having a big enough sample does not mean that the FPP and FPR will be bound to 5\%.\\

There are, of course, factors that are not under the control of the researcher, such as the correlation between the covariates and the dependent variable. But it is still worth a mention, that the higher the correlation between the covariates and the dependent variable, the easier it is to find a significant model. This is the case for both exploratory analyses and for a preregistered analysis. However, it is less clear how to solve this problem. Study designs with common method bias (e.g., measuring all covariates in one survey) could be particularly problematic due to  the increased correlation between the covariates \citep{podsakoff2003}. A potential remedy could be to report correlation matrices which would allow readers to assess the inflated risk of false positive findings.  \\ 

To sum up, using several researcher flexibilities increases the risk of finding a model with a significant effect even though no true effect is present. However, preregistration does not seem to be enough to bring the FPP and FPR down to the desired level of 5\%. We therefore made the following recommendations to reduce the probability of getting a false positive result. 

\subsection{Guidelines for researchers}

\subsubsection{Follow the principles of open science and use preregistration}
This reduces the number of researcher flexibilities and is therefore the most important step towards reducing the FPP. Researchers should therefore follow the already developed guidelines \citep{Nosek2015}. This means that research should be preregistered and all raw data and analyses code should be made available for other researchers to make it easier to see if any mistakes or mentioned flexibilities occurred during the analysis. 
\subsubsection{Use Bonferroni corrections when looking at interactions.}
A Bonferroni correction should be used when running regressions with interaction effects. If this is not done, the FPR will be higher than 5\%, and therefore the FPP would also be higher than 5\%. In some cases the correction can lower the FPR to less than 5\%, but we believe that this is a better outcome than having one that is higher than 5\%. 
\subsubsection{Large samples do not protect against FPP and FPR}
Having a large enough sample does not legitimize exploratory analyses. In general, the sample size only affects the power of the study and the precision of the estimates, it does not remedy the FPR and FPP. 

\subsection{Guidelines for reviewers and editors}

\subsubsection{Look for correction of p-values}
If multiple comparisons were made or interaction effects were used, there should be a correction of the p-values.
\subsubsection{Require that main effects always follow interaction effects}
A reviewer should never accept an interaction effect to be true if the main effects are not present and the variables are binary and dummy coded. 
\subsection{Exploratory analysis}
If exploratory analysis have been made, there should never be made any conclusions on these if the measurement of effect is p-values. Exploratory analysis still have a place within research, but concluding on these is a bad idea.  

\subsection{Additional contributions}
The size of a given model set and its permutations may not only be of interest to the open science community. Our description of model sets could also be of interest to researchers that use machine learning as a model selection tool. Since researchers who work with machine learning rarely care about one specific variable but rather about the predictability of a general model, using the sets where HCI is included is not always meaningful. Instead, what matters is whether the researcher will allow for interactions between the independent variables. The calculations of the model sets are therefore the same as if there was a variable of interest, but excluding the set that has HCI in it. This suggests that considering the requirement that the main effect should follow along with the interactions, the sets of interest are ME and ME + CCI. With no such requirements, the sets of interest are Ma, CCI, and ME + CCI. The number of models with and without restrictions, different number of variables, and how to calculate them can be found in Table SI9 and Table SI10. 


 
