\section{Method}
Focusing on the different flexibilities, we investigated the FPP and FPR for a variable that was uncorrelated with any other variable using a simulation. We used the previously discussed flexibilities i.e., different model specifications, outlier deletion present or absent, several dependent variables, and different sample sizes. These were tested using different correlations between the dependent variable and the covariates, and different data structures. Even though in some simple cases it would be possible to calculate a closed-form solution for the FPP and FPR (e.g., when looking at only one main effect), we used a simulation since it was not clear how the combination of different flexibilities used here would impact the FPP and FPR.\\

\subsection{Model Set}
When a researcher has to select which model(s) to use for testing a hypothesis, there are a lot of different decisions that can be made regarding what variables to collect and how they should enter the model. Under a completely randomized experiment, it would only be necessary to focus on the variable of interest, which we define as $h_1$, and the dependent variable, $y$ \citep{angrist2008mostly}. However, in many cases a researcher is either interested in how the variable of interest interacts with other variables or there is a need to control for other variables, which we call covariates and denote as $X=(x_1,x_2,..,x_n)$. For instance, this could be the case in the experimental setting where no complete randomization could be obtained or for observational data where it is necessary to control for different variables to avoid bias \citep{angrist2008mostly}. We, therefore, needed to build the model set having these additional covariates in mind. \\ 
To better understand the building of the model sets, we divided the models into seven sets based on different interaction structures. The first three sets contained the variable of interest and simple interactions, whereas the last four sets were the combinations of these three sets. An example of the first three model sets can be seen in Table 1 (excluding the constant and the coefficient in front of each variable for the sake of simplicity). The first set included models that contained only the main effects of the variable of interest and of the covariates (ME); the second set included models that contained the main effect of the variable of interest and interactions between the variable of interest and the covariates (HCI); and the last set included models that contained the main effect of the variable of interest and interactions between the covariates (CCI).
To obtain the last four model sets, we needed the combinations of the first three model sets. There were two possible choices: restricting our sets so that the main effects were always present when there was an interaction or allowing for interactions without including any main effects. In Table 2, we show the combination of all sets where the main effects are always included provided there is an interaction term. The other case, where the main effects are not required to follow, can be seen in the Supplementary Material in Table S1. \\

\begin{table}[]
\caption{}
\caption*{\footnotesize An overview of the first three model sets when there are two covariates and one dependent variable. Here $h_1$ is the variable of interest and $x_1$ and $x_2$ are covariates. The ME set contains all the main effects, the HCI set consists of the interactions between the variable of interest and the covariates, and the CCI set includes the interactions between the covariates.}
\centering
\begin{tabular}{cc}
\toprule
Model set & Models \\ 
\midrule
\multirow{4}{*}{ME} & $y=h_1$ \\ & $y=h_1+x_1$ \\ & $y=h_1+x_2$ \\ & $y=h_1+x_1+x_2$  \\ & \\
\multirow{3}{*}{HCI} & $y=h_1+h_1x_1$ \\ & $y=h_1+h_1x_2$ \\ & $y=h_1+h_1x_1+h_1x_2$  \\& \\
CCI & $y=h_1+x_1x_2$ \\ 
\bottomrule
\end{tabular}
\end{table}


\begin{table}[hbt!]
\centering
\caption{}
\caption*{\footnotesize An overview of all of the model sets when there are two covariates and one dependent variable with the restriction that main effects should be present when having interactions between variables. The ME set contains all of the main effects; the ME + HCI set includes the main effects and interactions between the variable of interest and the covariates; the ME + CCI set contains the main effects and  interactions between the covariates; the ME + HCI + CCI set contains the main effects, the interactions between the variable of interest and covariates, and the interactions between the covariates; the HCI, CCI and HCI + CCI sets are empty sets since they contain the interactions but not the required main effects.}
\begin{threeparttable}
\begin{tabular}{cc}
\toprule
Model set & Models \\ 
\midrule
\multirow{4}{*}{ME} & $y=h_1$ \\ & $y=h_1+x_1$ \\ & $y=h_1+x_2$ \\ & $y=h_1+x_1+x_2$  \\ & \\
\multirow{1}{*}{HCI} & Empty set  \\& \\
CCI & Empty set  \\ & \\
\multirow{5}{*}{ME + HCI} & $y=h_1+x_1+h_1x_1$  \\ & $y=h_1+x_2+h_1x_2$  \\& $y=h_1+x_1+x_2+h_1x_1$  \\& $y=h_1+x_1+x_2+h_1x_2$  \\& $y=h_1+x_1+x_2+h_1x_1+h_1x_2$ \\ & \\
ME + CCI & $y=h_1+x_1+x_2+x_1x_2$ \\ & \\
HCI + CCI & Empty set \\ & \\
\multirow{3}{*}{ME + HCI + CCI} & $y=h_1+x_1+x_2+h_1x_1+x_1x_2$ \\ & $y=h_1+x_1+x_2+h_1x_2+x_1x_2$ \\ & $y=h_1+x_1+x_2+h_1x_1+h_1x_2+x_1x_2$ \\
\bottomrule
\end{tabular}
\begin{tablenotes}
\textit{Note}: If we require that main effects have to follow all interactions, the combination of the HCI and CCI sets will always be empty. This is because there are no main effects related to the covariates in either of these sets and therefore their combination would not fulfill the restriction that main effects need to be present when using interactions. This would not be the case if we did not have this constraint (see Case 1 in the Supplementary Material).
\end{tablenotes}
\end{threeparttable}
\end{table}

Equation (1) is used to calculate the total number of models including all of the model sets given the number of covariates. Each part of Equation (1) can also be used to calculate the size of a specific model set. The derivation of this equation can be found in the Supplementary Material under Case 2. \\

\begin{equation} 
\begin{aligned}
\#models={} & \underbrace{\left(2^n\right)}_{ME}+\underbrace{\sum^n_{j=1}{\left(2^j-1\right)\binom{n}{j}}}_{ME + HCI} + \\ 
& \underbrace{\sum^n_{j=2}{\binom{n}{j}\left(2^{\frac{j\left(j-1\right)}{2}}-1\right)}}_{ME + CCI} + \\
& \underbrace{\sum^n_{j=2}{\binom{n}{j}\left(2^j-1\right)\left(2^{\frac{j\left(j-1\right)}{2}}-1\right)}}_{ME + HCI + CCI}\ \  
\end{aligned}
\end{equation} 

where $n$ denotes the number of covariates collected and $\binom{n}{j}$ is a binomial coefficient, calculation of which is explained in the Supplementary Material under the Formula for Set Size section.
Equation (1) did not include the HCI, CCI, and HCI + CCI sets as these included interaction terms with no corresponding main effects, and were therefore empty sets. For the case where we had two covariates, the total number of models was calculated as follows: \\


\begin{equation*}
\centering
\left(2^2\right)+
\sum^2_{j=1}{\left(2^j-1\right) \binom{2}{j}}+
\sum^2_{j=2}{\binom{2}{j}\left(2^{\frac{j\left(j-1\right)}{2}}-1\right)}+  
\sum^2_{j=2}{\binom{2}{j}\left(2^j-1\right)\left(2^{\frac{j\left(j-1\right)}{2}}-1\right)}= \\
4+5+1+3*1=13 
\end{equation*}


The number of models in each model set for the different number of covariates given the restriction that main effects must always follow interaction effects can be seen in Table 3. The number of models, when there is no such restriction in place, can be seen in Table S6 in the Supplementary Material. \\

\input{R/Analysis/CodeFinal/ModelSize/ModelNumberTrue}

In the simulation, we focused on two to four covariates as this was enough to give us an idea of how the increase in the size of the model set affected the FPP and FPR. 

\subsection{Outlier Criteria}
Following the findings of \cite{Leyes2013}, we included four different outlier criteria. Three of the criteria were based on the standard deviation (2, 2.5, and 3), while the remaining one used the interquartile range \citep{Rousseeuw2011}. Each outlier criterion was used on the entire dataset and not only on individual variables. If an observation fulfilled the outlier criteria, the observation was omitted from the analysis.

\subsection{Collecting Multiple Dependent Variables}
As in \cite{Simmons2011}, we tested the effect of using several dependent variables on the FPP and FPR. One example could be when a researcher is not sure how to measure the dependent variable (e.g., student performance) and therefore chooses to use several variables (e.g., grades in mathematics, grades in physics, or the average grade in natural sciences) to make sure the construct is captured well. To test the consequences of collecting several dependent variables (\textit{r}=0.5), we tested having two such variables. Furthermore, we computed the average of the two dependent variables to yield a third dependent variable. With these three dependent variables, the model set expanded three times compared to when there was only one dependent variable. In other words, every time two dependent variables were generated, we ran three different regressions. 


\subsection{Data Generating Process}
As the goal of the simulation was to determine how often our variable of interest with no true effect could become significant, we made sure it was not correlated with the dependent variable or any other covariates. The variable of interest could have one of the following two distributions: a normal distribution (continuous variable) or a binomial distribution (binary variable). The covariates were simulated using the same distributions; however, all covariates generated in one simulation had the same distribution. As linear regressions were used, the dependent variable could only be normally distributed. Four different combinations of the variable of interest and covariates could be obtained using these types of distributions: a continuous variable of interest and continuous covariates; a binary variable of interest and continuous covariates; a continuous variable of interest and binary covariates; and a binary variable of interest and binary covariates. 
The correlation between $y$ and $X$ was set to three different levels: \textit{r} = 0.2; \textit{r} = 0.3; and \textit{r} = 0.4, which denote medium-strength correlations \citep{Cohen1989}. The correlation between the variable of interest and the covariates as well as the correlation between the covariates themselves was set to zero. The correlation matrix for the data structure when there was only one dependent variable is presented in Table S11 in the Supplementary Material. If a variable was generated as a normally distributed variable, it was generated with a mean of 0 and a standard deviation of 1, while binomial variables were generated with a 50\% chance of success in each trial. To test how the sample size affected the FPP and FPR, the simulation included samples with sizes ranging from 100 to 300 with increasing steps of 50. 

\subsection{Simulation}
In the simulation presented in the results section, we only included cases in which the variable of interest and covariates had the same distribution. The two other cases i.e., when the variable of interest was binary and the covariates were continuous and the other way around can be found in the results section of the Supplementary Material. When the effect of increasing sample sizes was not investigated, the sample was set to 200. When the effect of different correlation levels was not tested, the correlation between the dependent variable and covariates was set to \textit{r}=0.2.\\
We used R \citep{Team2018} to perform our simulation. When the covariates had a binomial distribution, the variables were simulated using the package BinNor \citep{Demirtas2014}. This was done to ensure that the correlation matrix would also hold under this data type. The data were analyzed with linear regressions. Every time $h_1$ became significant, either by itself or in an interaction with another variable, it was considered a “success". We ran 10,000 simulation iterations. The FPP was defined as \\

\[FPP_i=\left. \left\{\begin{array}{c}
1\ if\ h_1\ is\ significant\ in\ at\ least\ one \ of\ the\ tested\ models \\ 
0\ otherwise\  \end{array}
\right.\] 
\[FPP=\frac{\sum^{10000}_i{FPP_i}}{10000}\] 


Here FPP${}_{i}$ indicates if any of the models in the model set had a significant result. If that is the case, it takes the value of 1, otherwise 0. The FPR is the ratio of the models with a significant result and can be written as \\

\[FPR_i=\frac{\#models\ with\ significant\ result}{\#models\ in\ the\ model\ set}\] 
\[FPR=\frac{\sum^{10000}_i{FPR_i}}{10000}\] 



